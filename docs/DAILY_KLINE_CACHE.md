# 日K线缓存与增量拉取策略

## 1. 缓存结构

文件路径：`~/.config/qtrade/kline_cache.json`

```json
{
  "stocks": {
    "HK.00700": {
      "klines": [
        { "date": "2025-01-10", "open": 380.0, "close": 385.0, ... },
        { "date": "2025-01-11", "open": 385.0, "close": 390.0, ... }
      ],
      "last_fetched": "2025-06-01"
    }
  }
}
```

- 每只股票最多保留 150 条日K线，按日期升序排列
- `last_fetched`：该股票最后成功拉取日期，当天已拉取过的股票跳过，避免节假日或重启时重复请求
- 格式不匹配时视为无缓存，全量拉取

## 2. 逐只自适应拉取

每只股票独立判断拉取策略，不使用全局的"全量/增量"模式。

### 算法

```
对于每只股票:
  0. last_fetched == today → 跳过（当天已拉取）
  1. 无缓存 → 全量拉取 (daily_days, 默认 120 天)
  2. 有缓存 → 取缓存最后一条K线日期 last_date
     a. 计算 gap = today - last_date (自然日)
     b. 拉取天数 = max(gap + 5, 5)，上限 daily_days
     c. 拉取数据后，验证连续性（见下节）
  3. 拉取成功后，记录 last_fetched = today
```

### 为什么用 gap + 5

- `gap` 覆盖缺失的自然日
- `+5` 作为缓冲，确保与缓存尾部有重叠（交易日 vs 自然日差异、节假日等）
- 上限 `daily_days` 防止请求范围过大

## 3. 连续性验证（重叠检查）

增量拉取后，必须验证新数据与缓存尾部**日期重叠**，才能确认连续。

### 规则

```
缓存尾部日期 = last_date
新拉取的数据日期集合 = fetched_dates

if last_date ∈ fetched_dates:
    → 连续 ✓，执行 merge（按日期去重合并）
else:
    → 断裂 ✗，丢弃该股票旧缓存，用新数据全量替换
      如果新数据天数不足，再发起一次全量拉取 (daily_days)
```

### 为什么不用间隔天数判断

- 自然日间隔无法准确反映交易日间隔（周末 2 天、节假日 7+ 天）
- 不需要交易日历，重叠检查自动适配所有休市场景

### 断裂场景

| 场景 | gap (自然日) | gap+5 能覆盖？ | 处理 |
|------|-------------|---------------|------|
| 隔夜/周末 | 1~3 | 能 | merge |
| 小长假 | 3~5 | 能 | merge |
| 长假（春节/国庆） | 7~10 | 能（gap+5=12~15） | merge |
| 用户停用 2 周 | 14 | 能（gap+5=19） | merge |
| 用户停用 1 个月 | 30 | 能（gap+5=35） | merge |
| 用户停用半年 | 180 | 超过 daily_days 上限 | 全量替换 |

## 4. 新股处理

- 首次遇到（无缓存）→ 全量拉取 → API 返回上市以来全部数据（可能 < daily_days 条）
- 后续增量 → last_date 是最近交易日 → gap 小 → 正常增量 + 重叠验证
- 新股天然条数少，但只要日期接得上就是连续的

## 5. 断点续传

- 每拉取 10 只股票即存盘（save_cache）+ 同步 dashboard
- 程序中断后重启，已拉取的股票有缓存，未拉取的走全量
- 逐只判断保证每只股票的数据完整性独立

## 6. 市场权限

- 运行时检测：拉取时如果 API 返回权限相关错误（"permission"/"未开通"/"no quota"/"not available"），标记该市场无权限
- 同一市场后续股票直接跳过，避免重复请求
- 不依赖实时行情订阅状态

## 7. 限流

- FutuOpenD 历史K线接口有频率限制（约 10 次/30 秒）
- 逐只串行拉取，每只间隔 200ms
- 不支持并行（限频按账户计，多连接无法突破）
